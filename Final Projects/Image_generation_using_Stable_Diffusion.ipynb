{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d38d790-ca69-482c-87b1-0aca96914718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import keras_cv\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da903630-4bec-4f20-8802-c17857d94276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By using this model checkpoint, you acknowledge that its usage is subject to the terms of the CreativeML Open RAIL-M license at https://raw.githubusercontent.com/CompVis/stable-diffusion/main/LICENSE\n"
     ]
    }
   ],
   "source": [
    "model=keras_cv.models.StableDiffusion(img_height=512,img_width=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "789e1634-e911-42e3-9a24-ad407089d886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://huggingface.co/fchollet/stable-diffusion/resolve/main/kcv_diffusion_model.h5\n",
      "\u001b[1m1403944960/3439090152\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m3:53:41\u001b[0m 7us/step"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "URL fetch failure on https://huggingface.co/fchollet/stable-diffusion/resolve/main/kcv_diffusion_model.h5: None -- retrieval incomplete: got only 1403945237 out of 3439090152 bytes",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mContentTooShortError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\file_utils.py:311\u001b[0m, in \u001b[0;36mget_file\u001b[1;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir, force_download)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 311\u001b[0m     urlretrieve(origin, download_target, DLProgbar())\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\urllib\\request.py:276\u001b[0m, in \u001b[0;36murlretrieve\u001b[1;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m read \u001b[38;5;241m<\u001b[39m size:\n\u001b[1;32m--> 276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ContentTooShortError(\n\u001b[0;32m    277\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mretrieval incomplete: got only \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m out of \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m bytes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m         \u001b[38;5;241m%\u001b[39m (read, size), result)\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[1;31mContentTooShortError\u001b[0m: <urlopen error retrieval incomplete: got only 1403945237 out of 3439090152 bytes>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m images\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtext_to_image(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPhotograph of three dogs\u001b[39m\u001b[38;5;124m'\u001b[39m,batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras_cv\\src\\models\\stable_diffusion\\stable_diffusion.py:85\u001b[0m, in \u001b[0;36mStableDiffusionBase.text_to_image\u001b[1;34m(self, prompt, negative_prompt, batch_size, num_steps, unconditional_guidance_scale, seed)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtext_to_image\u001b[39m(\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     76\u001b[0m     prompt,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     81\u001b[0m     seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     82\u001b[0m ):\n\u001b[0;32m     83\u001b[0m     encoded_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_text(prompt)\n\u001b[1;32m---> 85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_image(\n\u001b[0;32m     86\u001b[0m         encoded_text,\n\u001b[0;32m     87\u001b[0m         negative_prompt\u001b[38;5;241m=\u001b[39mnegative_prompt,\n\u001b[0;32m     88\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m     89\u001b[0m         num_steps\u001b[38;5;241m=\u001b[39mnum_steps,\n\u001b[0;32m     90\u001b[0m         unconditional_guidance_scale\u001b[38;5;241m=\u001b[39munconditional_guidance_scale,\n\u001b[0;32m     91\u001b[0m         seed\u001b[38;5;241m=\u001b[39mseed,\n\u001b[0;32m     92\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras_cv\\src\\models\\stable_diffusion\\stable_diffusion.py:228\u001b[0m, in \u001b[0;36mStableDiffusionBase.generate_image\u001b[1;34m(self, encoded_text, negative_prompt, batch_size, num_steps, unconditional_guidance_scale, diffusion_noise, seed)\u001b[0m\n\u001b[0;32m    226\u001b[0m latent_prev \u001b[38;5;241m=\u001b[39m latent  \u001b[38;5;66;03m# Set aside the previous latent vector\u001b[39;00m\n\u001b[0;32m    227\u001b[0m t_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_timestep_embedding(timestep, batch_size)\n\u001b[1;32m--> 228\u001b[0m unconditional_latent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiffusion_model\u001b[38;5;241m.\u001b[39mpredict_on_batch(\n\u001b[0;32m    229\u001b[0m     {\n\u001b[0;32m    230\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatent\u001b[39m\u001b[38;5;124m\"\u001b[39m: latent,\n\u001b[0;32m    231\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimestep_embedding\u001b[39m\u001b[38;5;124m\"\u001b[39m: t_emb,\n\u001b[0;32m    232\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m: unconditional_context,\n\u001b[0;32m    233\u001b[0m     }\n\u001b[0;32m    234\u001b[0m )\n\u001b[0;32m    235\u001b[0m latent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiffusion_model\u001b[38;5;241m.\u001b[39mpredict_on_batch(\n\u001b[0;32m    236\u001b[0m     {\n\u001b[0;32m    237\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatent\u001b[39m\u001b[38;5;124m\"\u001b[39m: latent,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    240\u001b[0m     }\n\u001b[0;32m    241\u001b[0m )\n\u001b[0;32m    242\u001b[0m latent \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39marray(\n\u001b[0;32m    243\u001b[0m     unconditional_latent\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;241m+\u001b[39m unconditional_guidance_scale \u001b[38;5;241m*\u001b[39m (latent \u001b[38;5;241m-\u001b[39m unconditional_latent)\n\u001b[0;32m    245\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras_cv\\src\\models\\stable_diffusion\\stable_diffusion.py:439\u001b[0m, in \u001b[0;36mStableDiffusion.diffusion_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"diffusion_model returns the diffusion model with pretrained weights.\u001b[39;00m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;124;03mCan be overriden for tasks where the diffusion model needs to be\u001b[39;00m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;124;03mmodified.\u001b[39;00m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_diffusion_model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_diffusion_model \u001b[38;5;241m=\u001b[39m DiffusionModel(\n\u001b[0;32m    440\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_height, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_width, MAX_PROMPT_LENGTH\n\u001b[0;32m    441\u001b[0m     )\n\u001b[0;32m    442\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjit_compile:\n\u001b[0;32m    443\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_diffusion_model\u001b[38;5;241m.\u001b[39mcompile(jit_compile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras_cv\\src\\models\\stable_diffusion\\diffusion_model.py:111\u001b[0m, in \u001b[0;36mDiffusionModel.__init__\u001b[1;34m(self, img_height, img_width, max_text_length, name, download_weights)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m([latent, t_embed_input, context], output, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m download_weights:\n\u001b[1;32m--> 111\u001b[0m     diffusion_model_weights_fpath \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mget_file(\n\u001b[0;32m    112\u001b[0m         origin\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://huggingface.co/fchollet/stable-diffusion/resolve/main/kcv_diffusion_model.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[0;32m    113\u001b[0m         file_hash\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m8799ff9763de13d7f30a683d653018e114ed24a6a819667da4f5ee10f9e805fe\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[0;32m    114\u001b[0m     )\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_weights(diffusion_model_weights_fpath)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\file_utils.py:315\u001b[0m, in \u001b[0;36mget_file\u001b[1;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir, force_download)\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(error_msg\u001b[38;5;241m.\u001b[39mformat(origin, e\u001b[38;5;241m.\u001b[39mcode, e\u001b[38;5;241m.\u001b[39mmsg))\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mURLError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 315\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(error_msg\u001b[38;5;241m.\u001b[39mformat(origin, e\u001b[38;5;241m.\u001b[39merrno, e\u001b[38;5;241m.\u001b[39mreason))\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mException\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m):\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(download_target):\n",
      "\u001b[1;31mException\u001b[0m: URL fetch failure on https://huggingface.co/fchollet/stable-diffusion/resolve/main/kcv_diffusion_model.h5: None -- retrieval incomplete: got only 1403945237 out of 3439090152 bytes"
     ]
    }
   ],
   "source": [
    "images=model.text_to_image('Photograph of three dogs',batch_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b96d547-0ccb-4fd9-b6ea-3f14ac675f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images):\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    for i in range(len(images)):\n",
    "        ax = plt.subplot(1, len(images), i + 1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c88620e-305a-44d8-9651-a501b54d99bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
